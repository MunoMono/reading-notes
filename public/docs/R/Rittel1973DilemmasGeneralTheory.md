---
title: "Dilemmas in a general theory of planning"
authors: "Rittel, Horst W. J. and Webber, Melvin M."
year: 1973
journal: "Policy Sciences"
citation_key: Rittel1973DilemmasGeneralTheory
doi: "10.1007/BF01405730"
url: ""
bibliography: ../../refs/library.bib
csl: "https://www.zotero.org/styles/harvard-cite-them-right"
link-citations: true
last_updated: "Jan 09, 2026, 03:38 PM"
category: 1.1-Canonical-methods-texts---
# Scope of this note
This note covers the full article (pp. 155–169), with emphasis on: (1) the diagnosis of goal formulation and problem definition failures in planning (pp. 155–160); (2) the ten propositions that define “wicked problems” (pp. 160–167); and (3) the social context argument about plural publics and the collapse of a singular public good (pp. 167–169). It is integrated into the project spine by treating *epistemic drift* as a wicked condition: the problem of “what drift is” shifts with methods, records, and instruments, and the standards of adequacy shift with it.

## Purpose and aim
### What research question or objective is being addressed?
The paper asks why the dominant, analytic, “systems” conception of planning fails in the domains planners increasingly claim—social policy, public programmes, and large-scale urban governance. It argues that the failure is structural rather than merely technical: the most consequential planning problems are not “tame” puzzles but *wicked problems*, whose formulation is unstable, whose evaluation criteria are plural and contested, and whose interventions are irreversible in practice (pp. 155–166). The objective is therefore diagnostic and polemical: to reframe planning as a form of political judgement under conditions where scientific method cannot deliver closure (pp. 166–169).

## Methodology
### Describe the research design, methods and sample size.
This is a theoretical essay and critique. Its method is conceptual differentiation supported by illustrative claims about mid-20th-century planning (e.g., systems analysis, programme planning, and emerging social indicators). It proceeds in three moves:

1. **Problematisation of planning’s “professional support system”** at the junction of goal formulation, problem definition, and equity/value conflict (pp. 155–160).
2. **Formalisation of wickedness** into ten propositions, offered as a systematic description of why standard analytic planning breaks down (pp. 160–167).
3. **Sociological anchoring** of wickedness in plural publics, value heterogeneity, and the decline of a stable unitary “public welfare” notion (pp. 167–169).

There is no empirical sample, no data collection, and no evaluation design; the “evidence” is primarily argumentative force and plausibility within the authors’ planning milieu.

## Key findings and arguments
### Summarise the main results and conclusions
1. **The crisis is upstream: goals and problem definitions are not given.** Planning’s failures are traced less to optimisation technique than to the fact that policy goals are contested, moving targets, and are not discoverable by technical analysis alone (pp. 155–160).
2. **Wicked problems have a distinct epistemic structure.** The ten propositions specify why problem formulation, solution generation, and evaluation cannot be separated, and why “solving” is a form of situated judgement rather than truth-tracking (pp. 160–167).
3. **The planner is not a neutral expert but a political actor.** Because there is no value-free standpoint and no unitary welfare function, expertise becomes a form of participation in politics; the expert “also becomes a player” in the contested field of outcomes and values (pp. 168–169).

#### The ten propositions as an epistemic checklist (project-useful restatement)
The paper’s propositions can be translated into an explicit checklist for research design and method claims:

1. **No definitive formulation**: any “definition” of the problem implies a particular solution direction and framing (p. 161).
2. **No stopping rule**: work ends by exhaustion, budget, or politics rather than by logical completion (p. 162).
3. **Solutions are not true/false** but judged better/worse via plural criteria (p. 163).
4. **No immediate or ultimate test**: evaluation is delayed, partial, and contested (pp. 163–164).
5. **One-shot operations**: interventions cannot be cleanly undone; learning by trial is ethically and politically constrained (p. 163).
6. **No enumerable solution set**: neither “all possible solutions” nor “all possible consequences” can be listed (p. 164).
7. **Essential uniqueness**: apparently similar problems differ in consequential ways; analogies mislead (p. 164).
8. **Symptomatic embedding**: each wicked problem can be read as a symptom of another; causality is nested and disputable (p. 165).
9. **Explanatory pluralism**: multiple causal stories can fit; the choice among them rests on world-view and values (p. 166).
10. **No right to be wrong**: planners carry heightened accountability because their “experiments” affect real lives (pp. 166–167).

## Relevance
### How does it link to the research questions or framework?
The project’s framework concerns how epistemic drift becomes observable across (a) design methods, (b) institutional archives/records, and (c) multimodal computational reconstruction. This paper supports three core claims within that framework:

- **Framing is constitutive.** If problem formulation depends on solution conceptions, then method choice (including archival schemas and ML pipelines) is not a neutral downstream decision; it actively shapes what “drift” can be said to be p. 161.
- **Evaluation criteria are plural and political.** If “solutions” are judged better/worse rather than true/false, then research claims about reconstructing drift must be evaluated with explicit, plural criteria (e.g.,  fidelity, interpretability, harms, exclusions, utility) rather than “accuracy” alone (p. 163).
- **Accountability attaches to instruments.** The “no right to be wrong” proposition implies that research instruments that classify, reconstruct, or visualise drift should be treated as interventions with consequences, not as descriptive mirrors (pp. 166–167).

## What the authors bring to the table
### Key contributions and claims
- **A canonical conceptualisation of wickedness.** The ten propositions remain the most portable definition set, offering a rigorous vocabulary for why many planning (and design) problems resist standard problem-solving (pp. 160–167).
- **A critique of first-generation systems thinking in policy.** The paper positions “systems analysis” and the search for optimality as ill-suited to social policy where goals and constraints are politically contested and dynamically reformulated (pp. 155–163).
- **A reframing of expertise.** Expertise is redescribed as entangled with politics and value judgement, rather than as a method for escaping it (pp. 168–169).
- **A proto-ethics of intervention.** The paper articulates why experimentation and iterative correction—common in engineering and some design narratives—are ethically fraught when applied to public populations (pp. 163–167).

### How I respond to this evidence
- The researcher **builds on** the framing claim by treating epistemic drift as a wicked object: drift is not simply “found” in archives or model outputs; it is produced through successive framings (research questions, category systems, data selection, model objectives).
- The researcher **extends** the accountability claim to computational research: reconstruction tools are not neutral; they become part of institutional decision-making and can sediment new drift by stabilising particular interpretations.
- The researcher **challenges** the paper’s treatment of pluralism as largely symmetrical. In institutional life, publics are not only multiple; they are unevenly empowered. Archives, metrics, and models tend to amplify some voices and erase others. Wickedness is therefore not merely complexity; it is structured conflict under unequal conditions.
- The researcher **questions** the rhetorical move from “no definitive formulation” to an implied scepticism about analytic method. The paper is persuasive as critique, but it risks being read as a counsel of despair unless paired with workable practices of negotiation, documentation, and accountability.

## Positioning this work
### What this literature will do for my project
- **Provide a theoretical warrant for reflexive method.** It legitimises explicit documentation of framing decisions (including data schemas and modelling choices) as part of rigour rather than as ancillary “limitations”.
- **Support a plural evaluation regime for reconstructions.** It justifies why a reconstruction cannot be “validated” by a single metric; evaluation must be negotiated across stakeholders and criteria.
- **Strengthen an argument about the politics of evidence.** It provides language for explaining why archives, indicators, and models are not mere inputs but arenas where value disputes are encoded.

### What this literature will not do
- **It will not specify operational procedures** for doing planning or design well under wickedness; the paper offers diagnosis more than method (pp. 160–169).
- **It will not resolve legitimacy questions** (who decides, by what authority, with what representation) beyond asserting the insufficiency of technical rationality (pp. 168–169).
- **It will not provide empirical substantiation** for its sociological claims about “contemporary publics” or the effects of particular planning approaches; these remain asserted rather than demonstrated (pp. 167–169).

## Project integration
### Why it helps the project (evidence-linked)
- **Method-as-framing evidence.** “The information needed to understand the problem depends upon one’s idea for solving it” provides a direct textual basis for treating the project’s three strands (methods, archives, ML reconstruction) as co-productive of the object of study (p. 161).
- **Plural evaluation evidence.** The claim that there are no true/false answers—only better/worse judgements—supports the project’s move from accuracy claims to *accountable interpretability* and stakeholder-grounded evaluation (p. 163).
- **Irreversibility evidence.** The “one-shot operation” proposition justifies caution about deploying classificatory or reconstructive tools into institutional settings where outputs can harden into policy reality (p. 163).
- **World-view evidence.** The proposition that explanatory choice reflects world-view underwrites the project’s insistence on making modelling assumptions explicit (objective functions, label regimes, similarity metrics) and contestable (p. 166).
- **Accountability evidence.** The argument that the planner has no right to be wrong translates, in this project, into an obligation to treat reconstruction outputs as ethically charged interventions, especially where they feed governance or reputational systems (pp. 166–167).

### Hooks into the project
- **Workstreams →**
  - *WS1: Methods lineage and epistemic drift* (how “design methods” codify frames; how frames shift historically).
  - *WS2: Archives, records, and institutional memory* (how record-making practices stabilise or distort frames over time).
  - *WS3: Multimodal reconstruction instruments* (how models operationalise frames; how visual analytics makes drift “seeable”).
- **Deliverables →**
  - Literature review chapter: wickedness as epistemic and evaluative condition for DDR.
  - Methods chapter: “framing log” protocol (documenting categories, exclusions, and evaluative criteria).
  - Evaluation appendix: plural rubric for reconstruction outputs (fidelity, interpretability, stakeholder utility, risk).
  - Reflective portfolio: instances where the research itself encounters wickedness (conflicting criteria; shifting problem definitions).
- **Stakeholders →**
  - Design researchers and supervisors (method legitimacy and contribution claims).
  - Archivists/record managers (classification, description, and access decisions).
  - Institutional partners (policy/organisation contexts where reconstructions may be used).
  - Computational collaborators (model objectives, validation, and interpretability practices).

### Use across the methods spine
- [x] Framing and theory
- [x] Study design
- [x] Data collection and instruments
- [x] Analysis and models
- [x] Synthesis and interpretation
- [x] Reporting and communications

## Critical evaluation
### Strengths
- **Operational clarity without false precision.** The propositions are concrete enough to guide method critique (e.g., “no stopping rule”, “one-shot operations”) while avoiding naïve quantification (pp. 161–165).
- **A disciplined refusal of technocratic closure.** By insisting that many policy questions cannot be solved by optimisation, the paper punctures a persistent tendency in design/tech to treat value conflict as an engineering constraint (pp. 162–163).
- **Ethical seriousness.** The irreversibility and accountability claims foreground human consequences, a corrective to “move fast” cultures of intervention (pp. 163–167).
- **Transfer value for design research.** The argument maps cleanly onto design briefs, stakeholder negotiation, and evaluation regimes—precisely where practice-led research often struggles to justify rigour.

### Weaknesses and limitations
- **Empirical thinness and historical specificity.** The paper relies on broad generalisations about planning, public protest, and social indicators. Its descriptive claims about society’s trajectory and planning practice are not empirically grounded in the text (pp. 155–160; 167–169).
- **A rhetorical risk of immunising work from critique.** If read carelessly, “wickedness” becomes an alibi: because problems are wicked, any result can be defended as “situated” and therefore beyond evaluation. The paper does not supply safeguards against this misuse.
- **Under-theorised power and institutions.** The paper foregrounds pluralism but gives limited analytic purchase on how institutions distribute voice, how archives and metrics privilege particular actors, and how expertise is legitimised. Wickedness here is framed as complexity plus plural values, rather than conflict structured by power.
- **Ambiguity about what replaces first-generation rationality.** While “second-generation” implications are gestured towards, the paper does not fully articulate practical governance mechanisms (deliberation design, accountability regimes, representational fairness) that would make its critique actionable.

### Author’s credibility
The authors write from a leading planning-intellectual environment and address contemporaneous policy/operations research debates. Their credibility is historical and disciplinary: the text has become canonical, but canonisation should be treated as a sociological fact, not as proof of completeness. The paper’s authority can itself be read as part of how “wickedness” discourse travels and stabilises in design and policy.

### Contextual validity
The argument is rooted in mid-century Western planning contexts, yet its core epistemic claims (unstable problem formulation; plural evaluation; irreversible interventions) generalise to many contemporary design-research settings. Transfer is nonetheless conditional: institutional arrangements, data regimes, and participation structures can mitigate or intensify wickedness. The paper’s generality is a strength for theory-building and a limitation for situated method guidance.

### Comparisons
- **With reflective practice traditions:** The paper shares the premise that framing is central and that practice is iterative, but it is sharper about the political nature of evaluation and accountability (cf. Schön’s reflective practice, later).
- **With classification/records scholarship:** The propositions anticipate later work that shows how categories shape realities (e.g., infrastructures and standards), yet the paper does not explicitly analyse classification as a technology of power—an opening for the project to develop.
- **With contemporary computational policy tools:** The critique aligns strongly with concerns that algorithmic systems operationalise contested values while presenting output as neutral. The paper offers a pre-digital vocabulary for today’s model governance debates.

## Interpretation
### Analysis and insights
The paper can be read as a theory of *why observation fails to settle disputes* in public life. If there is no definitive formulation and no decisive test, then “more data” does not necessarily bring closure; it often widens the space of contestable interpretations. For epistemic drift, this implies:

- **Drift is not merely a measurement error** but a predictable outcome of shifting frames, contested criteria, and institutional memory practices.
- **Archives and models are not passive repositories**; they are sites where particular world-views and value commitments are encoded and made durable.
- **Visualisations and reconstructions should be treated as arguments.** They require provenance, framing logs, and stakeholder-readable caveats, because they will otherwise function as technocratic closure devices.

### Critical thinking and rigour
The argument’s rigour is conceptual: it constructs a typology-like set of propositions and uses them to show contradictions in “tame” planning assumptions. Its critical tools include:
- **Epistemic critique** (limits of truth-conditional evaluation in policy),
- **Ethical critique** (irreversibility and accountability),
- **Sociological critique** (plural publics and shifting values).

However, the paper’s clarity also creates an interpretive trap: the propositions are sufficiently memorable to harden into doctrine. The project can use them more rigorously by treating them as hypotheses to be *operationalised and evidenced* within design-research cases (e.g., where exactly does “no stopping rule” appear in archival practice or model iteration, and who benefits from the stopping decision?).

## Evidence to quote or paraphrase
- 'The information needed to understand the problem depends upon one’s idea for solving it.' (p. 161)
- 'There are no true or false answers … there are only good or bad answers.' (p. 163)
- 'The planner has no right to be wrong.' (p. 166)
- **Paraphrase:** Because policy interventions cannot be cleanly undone, each attempt counts; the possibility of controlled trial-and-error is limited, so learning is politically and ethically constrained. (p. 163)
- **Paraphrase:** Competing causal explanations can each appear plausible; choosing among them ultimately reflects a world-view rather than purely logical inference. (p. 166)
- **Paraphrase:** In a plural society, the expert cannot stand outside politics; expertise becomes one more form of participation in contested outcomes. (pp. 168–169)

## Related works
- Churchman, C. W. (1967) ‘Wicked problems’ (precursor named in the paper) [@Rittel1973DilemmasGeneralTheory, p. 155].
- Simon, H. A. (1956/1957) *Administrative Behavior* / bounded rationality (background to “satisficing”; conceptually adjacent to pp. 163–164).
- Lindblom, C. E. (1959) ‘The science of muddling through’ (incrementalism; echoed in discussion around pp. 165–166).
- Schön, D. A. (1983) *The Reflective Practitioner* (framing and reflective action; later design-research canon).
- Jones, J. C. (1970) *Design Methods*; Archer, B. (1960s) systematic design; Cross, N. (1982) designerly ways of knowing (design-methods lineage relevant to WS1).
- Bowker, G. C. and Star, S. L. (1999) *Sorting Things Out* (classification as politics; deepens the paper’s under-theorised power dimension).
- Schwartz, J. M. and Cook, T. (2002) (archives/records and power; operationalises the institutional asymmetries the paper glosses).
- Drucker, J. (2014) *Graphesis* (visual epistemology; relevant to how “seeing” drift is constructed).
- Bender, E. et al. (2021) (limits and risks of large-scale language models; contemporary analogue of technocratic closure risks).
- Valleriani, M. et al. (2019) (epistemic communities and knowledge evolution; offers an empirical counterpart to drift claims).

## Questions for further research
- How can a practice-led design research project specify *accountable stopping rules* for analysis and modelling iterations when criteria remain plural and contested?
- What governance mechanisms (participatory design, audit trails, institutional review) best prevent “wickedness” from becoming an alibi for unaccountable expertise?
- How does institutional record-keeping (classification, retention, description) intensify or mitigate wickedness by stabilising certain framings over others?
- What would it mean to operationalise the ten propositions as *empirical diagnostics* in case studies of design methods, archives, and multimodal reconstruction?
- How can reconstruction tools expose their world-view commitments (labels, similarity metrics, feature choices) in forms that stakeholders can contest meaningfully?
