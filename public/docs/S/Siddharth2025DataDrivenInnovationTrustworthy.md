---
title: "Data-driven innovation for trustworthy AI"
authors: "Siddharth, L. and Luo, Jianxi"
year: 2025
journal: "She Ji: The Journal of Design, Economics, and Innovation"
citation_key: Siddharth2025DataDrivenInnovationTrustworthy
doi: "10.31219/osf.io/a3d6z"
url: "https://osf.io/a3d6z"
bibliography: ../../refs/library.bib
csl: "https://www.zotero.org/styles/harvard-cite-them-right"
link-citations: true
last_updated: "Nov 28, 2025, 08:07 AM"
category: 4.3-RAG/XAI/provenance---
# Scope of this note
Focuses on how Siddharth and Luo’s *double-hump model* operationalises 'trustworthy AI' principles through design and innovation processes. The paper provides an integrative bridge between engineering-driven AI governance and design-led methods of knowledge structuring, highly relevant to the DDR project’s RAG-based framework for archival trust, explainability, and traceability.

## Purpose and aim
The paper seeks to transform generic ethical guidelines for *trustworthy AI*—such as fairness, robustness, explainability—into operational, designable processes. It asks: how can data-driven innovation models guide both the **creation** and **assessment** of AI-centric artefacts so that trustworthiness becomes measurable and actionable rather than aspirational?

## Methodology
A conceptual synthesis grounded in Luo’s *double-hump model of data-driven innovation* (2023). The model merges design creativity theory, engineering management, and computational methods (e.g., patent mapping, LLMs, knowledge graphs, and RAG pipelines). Rather than empirical testing, it advances a structured “roadmap” showing how different data sources, computational techniques, and design practices can be mobilised across four phases: discovering, evaluating, generating, and evaluating again.

## Key findings and arguments
1. **Operationalisation of trust:** Institutional principles (EU HLEG-AI, UNESCO, NIST) remain too abstract; the double-hump model embeds them in design routines and computational tools.  
2. **Data as driver, not fuel:** The model reconceives data as a creative agent capable of revealing opportunity spaces and design rationale, rather than a passive input.  
3. **Retrieval-Augmented Generation (RAG):** Demonstrated as a mechanism for traceable, explainable concept generation, linking large language models to patent and research corpora.  
4. **Ontological foundation:** Argues that trustworthy AI needs an ontology comparable to those in design function theory, enabling computational assessment of artefacts, domains, and organisations.  
5. **Policy alignment:** Maps the EU AI Act’s risk classes (prohibited–minimal) to Maslow’s hierarchy of needs, reframing compliance as design intent.

## Relevance
Trustworthiness, transparency, and ontological grounding resonate directly with the DDR project’s goal to recast archival classification as an epistemic infrastructure. Siddharth and Luo’s framework mirrors the DDR taxonomy’s ambition to operationalise pluralist epistemologies through computational pipelines.

## Project integration
### Why it helps the project (evidence-linked)
- The *double-hump model* provides a precedent for integrating qualitative design reasoning with computational architectures such as RAG (pp. 270–273).  
- Their emphasis on explainability, traceability, and auditability parallels DDR’s reclassification logic: making archival inference transparent to users and auditors [oai_citation:1‡Research SoW v2.docx](file-service://file-2FeMVazHMWB1odfeFTcSFF).  
- The ontological turn in *trustworthy AI* offers a theoretical analogue for DDR’s “critical taxonomy”—both transform classification from description into inquiry.

### Hooks into the project
- **Workstreams →** Computational enrichment & ontology building.  
- **Deliverables →** Taxonomy-driven interface with traceable knowledge graphs.  
- **Stakeholders →** Cultural institutions seeking demonstrable auditability of digital heritage tools.

### Use across the methods spine
- [x] Framing and theory  
- [x] Study design  
- [x] Data collection and instruments  
- [x] Analysis and models  
- [x] Synthesis and interpretation  
- [x] Reporting and communications

## Critical evaluation
### Strengths
- Integrates design innovation with AI ethics through a coherent process model.  
- Advances concrete computational instruments (RAG, NLP, patent maps) that bridge creative ideation and risk governance.  
- Provides a rare design-centric response to policy frameworks such as the AI Act.

### Weaknesses and limitations
- The model is largely theoretical and untested; its feasibility across social or cultural domains is assumed rather than proven.  
- Heavy reliance on structured data (patents, news, legal documents) risks reinforcing technocratic biases.  
- Ethical reflexivity—who defines trustworthiness—is addressed less critically than technically.

### Author’s credibility
L. Siddharth (George Washington University) and Jianxi Luo (City University of Hong Kong) are leading figures in systems engineering and data-driven design. Luo developed *InnoGPS* and the *double-hump* framework; Siddharth extends it into knowledge-graph and RAG applications, evidencing methodological authority.

### Contextual validity
The argument generalises across sectors—engineering, healthcare, policy—but empirical validation remains thin. It is conceptually strong, institutionally neutral, and computationally plausible, making it valuable as a design-research scaffold.

### Comparisons
Aligns with Díaz-Rodríguez et al. (2023) on responsible AI and Alfrink et al. (2024) on contestability loops but differs in treating design process models as the medium of ethical implementation, not merely audit criteria.

## Interpretation
### Analysis and insights
Siddharth and Luo reframe the ethics of AI as a design problem: trust emerges through procedural transparency, not post-hoc compliance. Their RAG-based workflow anticipates the DDR project’s use of semantic retrieval and graph reasoning for epistemic audit. Just as they advocate ontological grounding for trustworthy AI, the DDR taxonomy aims to build ontological coherence for archival reliability. The double-hump model thus becomes a transferable epistemic engine: a way of linking institutional ethics to computational design, and by extension, linking historiographic reflexivity to infrastructure design.

### Evidence to quote or paraphrase
- 'Data can act as a driver, not merely as a fuel, for design and innovation processes' (p. 267).  
- 'We propose developing an ontological basis of trustworthy AI… to enable computational assessments of AI-centric artifacts, their domains, and the organizations that develop or manage them' (p. 276).  
- **Paraphrase:** Trustworthy AI requires embedding ethical principles within the very mechanics of design rather than applying them retrospectively (p. 269).

## Related works
- Díaz-Rodríguez et al. (2023) *Connecting the Dots in Trustworthy AI*  
- Alfrink et al. (2024) *Envisioning Contestability Loops*  
- Luo (2023) *Data-Driven Innovation* IEEE TEM  
- Radclyffe et al. (2023) *Assessment List for Trustworthy AI*  
- Kaur et al. (2023) *Trustworthy Artificial Intelligence: A Review*  

## Questions for further research
- How can the ontological layer proposed by Siddharth and Luo be adapted to non-technical archives like DDR?  
- What metrics would demonstrate “trustworthiness” in historiographic or curatorial systems?  
- Could DDR’s multimodal taxonomy serve as a prototype for domain-specific trustworthy knowledge infrastructures?