---
title: "Design methods"
authors: "Jones, John"
year: 1992
journal: "John Wiley & Sons"
citation_key: Jones1992DesignMethods
doi: ""
url: ""
bibliography: ../../refs/library.bib
csl: "https://www.zotero.org/styles/harvard-cite-them-right"
link-citations: true
last_updated: "Jan 09, 2026, 03:38 PM"
category: 1.1-Canonical-methods-texts---
# Scope of this note
This note critically reads the supplied extract (PDF pp. 1–39; **book pp. 45–86**), centred on Chapter 4 (“The new methods reviewed”), Chapter 5 (“The design process disintegrated”) and the opening of Chapter 6 (“Choosing strategies and methods”). It treats Jones’s project as an attempt to externalise design thinking, classify method families (black box / glass box / self-organising), and propose a strategy-selection apparatus (input–output chart) for managing uncertainty in system-level design. (pp. 45–86)

## Purpose and aim
### What research question or objective is being addressed?
Jones aims to explain what “new” design methods have in common, why they proliferate as diagrams, matrices and networks, and how they can be combined into workable strategies rather than treated as mutually exclusive recipes. The objective is managerial and epistemic: to make previously private design thinking public, shareable and controllable at the systems level—without collapsing into either “mystical psychology” or “deterministic logic”. (pp. 45–49)

## Methodology
### Describe the research design, methods and sample size.
The work is methodological synthesis and theory-building, not an empirical study with a sample. In this extract Jones:
- reviews a heterogeneous corpus of mid-century “design methods” and reframes them as partial instruments within larger strategies, rather than stand-alone recipes. (pp. 45–47)
- uses conceptual modelling (cybernetic metaphors and block-diagram reasoning) to present designers as black boxes, glass boxes and self-organising systems, exposing the assumptions and limits of each stance. (pp. 46–50)
- proposes “project control” criteria as a pragmatic governance layer for design-team action under uncertainty (including early identification of high-penalty decisions and a cost-of-not-knowing logic). (pp. 57–59)
- advances a classification and selection device (the input–output chart, Fig. 6.8) and demonstrates its intended use via worked/hypothetical scenarios. (pp. 79–82)
- argues normatively for coupling method to measurement, to avoid design methodology degenerating into self-referential talk. (p. 54)

## Key findings and arguments
### Summarise the main results and conclusions
1. **Common aim: externalisation of design thinking.** New methods are positioned as attempts “to make public the hitherto private thinking of designers; to externalize the design process”, using formal representations that allow participation beyond the designer’s personal experience. (p. 45)
2. **Three epistemic stances with distinct failure modes.** “Black box” accounts legitimise tacit competence but resist audit; “glass box” accounts privilege planned sequences but over-assume stable objectives and problem structure; “self-organising” accounts shift attention to strategy control under uncertainty. (pp. 46–50)
3. **System innovation breaks linearity; method must manage circularity.** In novel problems, objectives, variables and criteria remain unstable until critical decisions are taken; “circularity” and backtracking are structural rather than accidental. “Research actions” (predictor stages) can reduce expensive reversals, but only when their informational value exceeds their cost. (pp. 52–55)

## Relevance
### How does it link to the research questions or framework?
Jones is directly useful where the doctoral project treats **methods as epistemic instruments** rather than neutral tools, and where epistemic drift is tracked across (i) design methods, (ii) institutional recording, and (iii) computational reconstruction.

- **Strand 1 (historical emergence in design research):** Jones supplies a canonical explanation for why method discourse moves towards diagrams and explicit procedures under system complexity: externalisation is framed as the shared driver of “new methods”. (pp. 45–47)
- **Strand 2 (material recording, structuring, obscuring):** Jones’s categories and charts formalise what counts as “inputs”, “outputs”, “objectives” and “critical decisions”. This performs classificatory work: it stabilises attention and renders certain uncertainties recordable while relegating others to tacit judgement. (pp. 57–59; pp. 79–82)
- **Strand 3 (ML/visual-analytics reconstruction):** the warning about network diagrams—how easily one forgets their relation to the “real world” and believes that what can be drawn can also be produced—translates cleanly into model-based inference and visual analytics. (p. 62)

## What the authors bring to the table
### Key contributions and claims
- **A unifying claim about “new methods”:** they externalise design thinking to make it more manageable and participatory at the systems level. (p. 45)
- **A diagnostic typology:** black box / glass box / self-organising metaphors, each tied to characteristic limitations and epistemic risks. (pp. 46–50)
- **A control agenda:** explicit criteria for design project control, including early identification of high-penalty decisions and a penalty-versus-cost rule for research actions. (pp. 57–59)
- **A selection mechanism:** the input–output chart (Fig. 6.8) and “design strategy” as a configurable list of actions, not adherence to one method. (pp. 79–82)
- **A critique of methodological self-reference:** methodology becomes sterile if it is not linked to “measurement of what such thoughts are to achieve”. (p. 54)

### How the project should respond to this evidence
- **Building on:** Jones’s “strategy control” can be operationalised as an audit framework for the project’s method assemblage (data sources, modelling choices, interpretive thresholds), treating “critical decisions” as traceable points where drift can be observed and contested. (pp. 57–59)
- **Challenging:** Jones frames “transformation” as vital yet still “mysterious” in collaborative terms, leaving governance of contested framing under-specified; the project can extend this via archival and classification politics (who gets to frame, and whose frames become records). (pp. 70–71)
- **Informing practice:** divergence–transformation–convergence can scaffold practice-led cycles, but should be treated as a heuristic rather than a law; the project can specify what gets documented at each stage to make later synthesis defensible. (pp. 79–83)

## Positioning this work
### What this literature will do for the project
- **Advance the argument:** it provides a canonical, internally articulated rationale for representational formalisation (networks, matrices, charts) as a response to system complexity—supporting the claim that representation is an epistemic intervention with consequences. (pp. 45–47; p. 62)
- **Fill a gap:** it links method choice to uncertainty management (circularity vs linearity; predictor stages; cost-of-not-knowing), offering vocabulary for diagnosing where a research design over-claims control. (pp. 52–55)
- **Act as a hinge in the core constellation:** it bridges Archer-style systematic method discourse to later critiques of rationalisation and to the project’s concern with drift becoming infrastructural through recording and classification. (pp. 45–50; pp. 57–59)

### What this literature will not do
- **Boundaries and limitations for this project:**
  - it does not provide an empirically validated general theory of design behaviour; Jones explicitly answers that a general theory is not yet possible. **This is the sentence previously cited as `[oaicite:22]{index=22}` and it is on book p. 63.** (p. 63)
  - the input–output chart is explicitly framed as a “first attempt” at classification and “has not yet been tried out in practice”, limiting its authority as evidence rather than proposition. (p. 81)
  - power is only partially theorised: participation is treated largely instrumentally (to discover “what is critical”), not as conflictual politics of memory, accountability and exclusion. (pp. 81–82)
- **Questions left unanswered for this work:**
  - how to formalise collaborative “transformation” without degrading the capacity to control the design situation as a whole;
  - how to operationalise “relevance to the whole design situation” without collapsing into either rigid operationalism or unaccountable intuition. (pp. 70–73)

## Project integration
### Why it helps the project (evidence-linked)
- **Externalisation as historical mechanism:** Jones states that the shared feature of new methods is making design thinking public and diagrammable, enabling contribution from users and others outside the designer’s experience. This supports a claim about method as institutional interface. (p. 45)
- **Problem structure instability and drift:** Jones argues that identifying variables, objectives and criteria is “itself the major difficulty” in designing, because critical structure is unstable until decisions are taken. This supports modelling drift as changes in frames and criteria, not merely changes in solutions. (p. 52)
- **Method–measurement coupling:** Jones warns that design methodology risks becoming “thoughts-about-thoughts” unless tied to “measurement of what such thoughts are to achieve”. This warrants triangulating practice-led evidence with computational and archival traces. (pp. 54; 69)
- **Networks as epistemic trap:** Jones warns it is easy to forget the relation between network diagrams and the “real world” and to believe that whatever can be drawn can be produced. This transfers directly to model visualisation and ML inference. (p. 62)
- **Method as politics-by-other-means (proto-argument):** Jones frames methodologies as “mere symbolic contrivances”, rejecting both technocratic reification and anti-method animism. This is a useful hinge into later archival/classification critiques while retaining methodological agency. (p. 73)

### Hooks into the project
- **Workstreams →**
  - **Strand 1:** Method historiography of externalisation, diagrams and the move from product design to system designing. (pp. 45–47)
  - **Strand 2:** Classification and recording as governance of attention (inputs/outputs; critical decisions; what becomes reviewable). (pp. 57–59; pp. 79–82)
  - **Strand 3:** Computational instrumentation and visual-analytic caution (networks as seductive but fallible representations). (p. 62)
- **Deliverables →**
  - Methods chapter scaffold using divergence–transformation–convergence as an organising structure for practice-led cycles and documentation. (pp. 79–83)
  - Evaluation rubric: adapt “strategy control” criteria to assess research design decisions (data, models, interpretive penalties). (pp. 57–59)
  - Visual grammar: treat Jones-style networks and charts as antecedents to contemporary knowledge maps and model dashboards. (pp. 61–62; pp. 79–82)
- **Stakeholders →**
  - Supervisory and examination audiences (defence of methodological choices as uncertainty management). (pp. 57–59)
  - Institutional partners and archivists (implications for what is documented, classified and treated as “critical”). (pp. 57–59; p. 81)
  - Designers and tool builders (criteria for responsible externalisation and participatory strategy control). (pp. 45; 57–59)

### Use across the methods spine
- [x] Framing and theory
- [x] Study design
- [x] Data collection and instruments
- [x] Analysis and models
- [x] Synthesis and interpretation
- [x] Reporting and communications

## Critical evaluation
### Strengths
- **Clarity about partiality:** Jones refuses a master-method and treats methods as composable actions within strategies, reducing recipe fetishism. (pp. 45–47)
- **Operational insight without naïve rationalism:** the circularity/predictor-stage argument recognises that innovation defeats linear planning, yet proposes governance mechanisms to reduce expensive backtracking. (pp. 52–55)
- **Explicit meta-level stance on methodology:** the “symbolic contrivance” argument avoids both technocratic reification and anti-method mystification, creating room for critique without abandoning method. (p. 73)

### Weaknesses and limitations
- **Empirical thinness (in this extract):** several claims about what “works” rest on illustrative/hypothetical examples rather than systematic evidence, and Jones explicitly omits evidential review to stay “practical”. (p. 57; p. 70)
- **Ambiguous accountability in transformation:** transformation is diagnosed as decisive but “mysterious”; the extract is stronger on selecting methods than on governing contested frames in teams. (pp. 70–71)
- **Reification risk inside the chart:** the input–output chart embeds a particular epistemology (certainty/generality ordering; staged progress). Jones anticipates disagreement and flags it as untested. (p. 81)

### Author’s credibility
Jones writes as a design methodologist synthesising a large secondary literature for practical use. Credibility is strengthened by explicit admissions of judgement and uncertainty, but auditability is weakened where evidence is intentionally omitted to avoid a “tedious review”. (p. 57)

### Contextual validity
The argument is situated in the expansion from product design to system design under accelerating technological change. Transferability is strongest where problems are multi-actor, interdependent and uncertain; it is weaker where objectives can legitimately be fixed early or where craft logics dominate. (pp. 45–47; pp. 52–53)

### Comparisons
- **Versus Archer (systematic method):** Jones resists confining intuition to an initial stage; he treats mixing judgement and calculation as ongoing and person/problem-specific. (p. 63)
- **Versus Schön (reflective practice):** Jones emphasises external representations and control criteria; Schön privileges inquiry-in-action and reframing, offering a thicker account of transformation-in-practice. (pp. 70–71)
- **Versus Rittel & Webber:** Jones’s instability diagnosis aligns with wickedness, but the response is method-composition and predictor actions rather than an explicit politics of problem definition. (pp. 52–55)
- **Versus Bowker & Star; Schwartz & Cook:** Jones provides proto-material for later classification politics (what becomes legible and recordable), but does not develop institutions, archives and consequences as primary objects. (pp. 57–59; p. 81)

## Interpretation
### Analysis and insights
Jones can be read as documenting an epistemic transition: from design-as-drawing and tacit authority to design-as-explicit strategy, diagrams and shared representations. The promise is participation and manageability; the hazard is fragmentation—splitting designing into intuitive, rational and procedural compartments that degrade control exactly where innovation depends on transformation. For the doctoral project, the key inference is that increased legibility can amplify epistemic drift unless strategy control is itself designed as participatory, revisable and accountable. (pp. 69–71; p. 81)

### Critical thinking and rigour
Jones deploys:
- **cybernetic reasoning** (black box / glass box / self-organising) to surface epistemic commitments; (pp. 46–50)
- **process theory** (circularity; divergence–transformation–convergence) to describe how uncertainty is increased, patterned and reduced; (pp. 52–55; pp. 79–83)
- **meta-methodological governance** (project-control criteria; cost-of-not-knowing) as a pragmatic rigour standard. (pp. 57–59)  
Rigour is strongest in conceptual clarity and in the demand for method–measurement coupling. It is weakest where claims rely on authorial judgement without traceable evidential support (explicitly framed as a practical trade-off). (pp. 54; 57)

## Evidence to quote or paraphrase
- **Quote:** “to make public the hitherto private thinking of designers; to externalize the design process.” (p. 45) (p. 45)
- **Quote:** “only too easy to forget about the relationship between the network and the real world … and to deceive oneself into believing that whatever can be drawn as a network can also be produced.” (p. 62) (p. 62)
- **Quote:** “Nothing like enough is yet known … to attempt an explanation that could be verified by observation and experiment.” (p. 63) (p. 63)
- **Quote:** “mere symbolic contrivances.” (p. 73) (p. 73)
- **Paraphrase:** Identifying variables, objectives and criteria is “itself the major difficulty” in designing, because the problem structure is unstable until critical decisions are taken. (p. 52) (p. 52)
- **Paraphrase:** The “main effect” of new design methods is to externalise and split designing into intuitive, rational and procedural (“thoughts-about-thoughts”) components, which helps manage systems-level complexity but risks fragmentation. (p. 69) (p. 69)
- **Paraphrase:** The input–output chart is a first attempt at classification and has not been tried in practice; disagreement and ambiguity are expected. (p. 81) (p. 81)

## Related works
- Archer, L.B. (1963–64; 1968) on systematic method and rational pictures of design process (a nearby target/foil for Jones).  
- Schön, D.A. (1983) on reflective practice, framing and inquiry-in-action (a complementary account of transformation-in-situ).  
- Rittel & Webber (1973) on wicked problems (parallel critique of linear rationalism; more explicit politics of problem definition).  
- Bowker & Star (1999); Schwartz & Cook (2002); Gilliland & Caswell (2016) on classification, archives and imaginaries (where Jones’s representational devices can be read as proto-infrastructures).  

## Questions for further research
- What is gained and lost—historically, ethically and epistemically—when design judgement is externalised into diagrams, charts and method taxonomies? (pp. 45; 69)
- How can collaborative “transformation” be instrumented (recorded, audited and contested) without freezing frames prematurely? (pp. 70–71)
- How should “the cost of not knowing” be operationalised in practice-led research that also uses computational models—what counts as penalty, and for whom? (pp. 57–59)
- When do networks and classifications become self-fulfilling infrastructures that narrow possible futures, rather than widening perceptual span? (p. 62)
- How can an ML/visual-analytics pipeline avoid Jones’s trap—mistaking drawable relations for producible realities—when reconstructing epistemic drift from traces? (p. 62)
